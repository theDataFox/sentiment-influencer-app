{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community 6\n",
      "pokecodeshop, GeekStoredotcom, EGX_Esports, PCPartPicker, TEAMEVGA, NVIDIAGeForceUK, Radeon, msiUSA, ClanTDK, OWCentral, engadget, CORSAIR, GIGABYTEUSA, AMDGaming, BlizzardCSEU_EN, ASUS, OverwatchEU, PlayDuelyst, YourOverwatchYT, PocketPixl, PlayOverwatch, overwatchleague, Twitch, TESLegends, tomshardware, PcCentric, techradar, NETDUMA, nvidia, OverwatchGG, pcgamer, metline, NVIDIAGeForce, PlayHearthstone, OmnicLab\n",
      "Community 8\n",
      "MagicOnline, delverslab, TOTALmtg, wizards_magic, StarCityGames, edhrec, GatheringMagic, deckstats, TolarianCollege, MTGatTCGplayer, MTGGoldfish, cardhoarder, magicprotour, CardmarketMagic, tappedout, scryfall, ManaleakCom, wandi1234, AxionNow, Team_Axion\n",
      "Community 9\n",
      "animetoday, FUNimation, VIZMedia, amiamihobbynews, MangaUK, Crunchyroll, mangacom, GoodSmile_US, DB_Legends, ViralRajyaguru, SonSonComics, SonSonPhotos\n",
      "Community 10\n",
      "SerebiiNet, OmniPoke, ThePokemonEvos, TeamMysticPGO, GoTeamMystic, Bulbagarden, NinEverything, thewossy, PokemonGoApp, pokebeach_wpm, NintendoSwitchC, MysticPGO, PokemonGoNews, Pokemon, RareCandyTCG, GamingHistorian, nintendolife, Bulbanews, NintendoUK, theSuperRodcast, PokemonUKGo, enjoifriend, NintendoEurope, NintendoAmerica, capsulecorpccg, PokemonNewsUK, PokemonLetsGoNS, Pokemon_cojp, Junichi_Masuda, BulbaNewsNOW, ZeldaWiki, NianticLabs, ZeldaUniverse, Bulbapedia, SixPrizes\n",
      "Community 13\n",
      "GMapsPlatform, hadoop, RLangTip, TIBCO, googlechrome, TwitterDev, TwitterAPI, inside_R, googlemaps, RegexTip, ds_ldn, pycoders, rstudio, TwitterEng, Android, UnixToolTip, udacity, R_Programming, kaggle, kdnuggets, analyticbridge, googledrive, codeorg, anacondainc, DataScienceCtrl, awscloud, Codecademy, github, jdevoo, KDnuggetsJobs, googledevs, Twitter, ThePSF, rstudiotips, Rbloggers, gmail, howtogeek, strataconf, SciPyTip, Google, SocialWebMining\n",
      "Community 14\n",
      "hsdecktracker, HSReplayNet, savingoceans, HSTopDecks, Hearthhead, ESLHearthstone\n",
      "Community 15\n",
      "VinceZampella, TheSixthAxis, TitanfallBlog, jonshiring, OverwatchSarah, OPM_UK, NetherRealm, CriterionGames, Sony, TFLegends, AskPlayStation, daedalic, GameSpot, asmrplays, PlayStation, pushsquare, Scalebound, IGNUK, engadgetgaming, TacticalGaming, HorizonForza, VG247, E3, steam_games, ScufGaming, EA, GameTrailers, Steep_Game, bioware, IGN, BethesdaStudios, ForzaMotorsport, DeeJ_BNG, PlayWarframe, MimimiProd, Titanfallgame, ElderScrolls, TrialsReport, SkillUpYT, GaslampASMR, Kotaku, thislukesmith, Polygon, PlayStationEU, UbisoftUK, the100_io, assassinscreed, theASMRnerd, DestinyTheGame, Respawn, EAStarWars, WeArePlayground, Ubisoft, N4G, PlayStationUK, Bungie\n",
      "Community 16\n",
      "ASRockInfo\n",
      "Community 17\n",
      "trygest\n",
      "Community 18\n",
      "DCComics, reedcomics, BatmanvSuperman, SuperheroNewsCB, GSUniverse, SuperHeroHype, SuperHeroStuff, BatmanNewsCom\n",
      "Calculating modularity for directed graph\n",
      "Modularity of such partition for network is 0.492\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# convert gml to json and add community\n",
    "\n",
    "# import libraries\n",
    "import argparse\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "from modularity_maximization import partition\n",
    "from modularity_maximization.utils import get_modularity\n",
    "import json\n",
    "\n",
    "#def graphmltojson(graphfile, outfile):\n",
    "    # \"\"\"\n",
    "    # Converts GraphML file to json while adding communities/modularity groups\n",
    "    # using python-louvain. JSON output is usable with D3 force layout.\n",
    "    # Usage:\n",
    "    # python convert.py -i mygraph.graphml -o outfile.json\n",
    "    # \"\"\"\n",
    "# G = nx.read_gml('influencer\\TheDataFox.gml')\n",
    "# print nx.info(G)\n",
    "#comm_dict = partition(G)\n",
    "for comm in set(comm_dict.values()):\n",
    "    print(\"Community %d\"%comm)\n",
    "    print(', '.join([node for node in comm_dict if comm_dict[node] == comm]))\n",
    "\n",
    "print('Modularity of such partition for network is %.3f' %\\\n",
    "      get_modularity(G, comm_dict))\n",
    "\n",
    "# adds partition/community number as attribute named 'modularitygroup'\n",
    "for n, d in G.nodes(data=True):\n",
    "    d['modularitygroup'] = comm_dict[n]\n",
    "\n",
    "# create a dictionary in a node-link format that is suitable for JSON serialization\n",
    "d = json_graph.node_link_data(G)\n",
    "with open('output.json', 'w') as fp:\n",
    "    json.dump(d, fp)\n",
    "\n",
    "# node_link = json_graph.node_link_data(G)\n",
    "# json = json_graph.dumps(node_link)\n",
    "\n",
    "# #Write to file\n",
    "# fo = open('output.json', \"w\")\n",
    "# fo.write(json)\n",
    "# fo.close()\n",
    "\n",
    "#\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser(description='Convert from GraphML to json. ')\n",
    "#     parser.add_argument('-i', '--input', help='Input file name (graphml)', required=True)\n",
    "#     parser.add_argument('-o', '--output', help='Output file name/path', required=True)\n",
    "#     args = parser.parse_args()\n",
    "#     graphmltojson(args.input, args.output)\n",
    "\n",
    "# graphmltojson('influencer\\TheDataFox.gml', 'influencer\\TheDataFox.json')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Twitter!\n"
     ]
    }
   ],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit_notify=True)\n",
    "\n",
    "print(\"Connected to Twitter!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directories we need\n",
    "if not os.path.exists(FOLLOWING_DIR):\n",
    "    os.makedirs(FOLLOWING_DIR)\n",
    "\n",
    "if not os.path.exists(USER_DIR):\n",
    "    os.makedirs(USER_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = lambda x: x.encode('ascii', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_follower_ids(centre, max_depth=1, current_depth=0, taboo_list=[]):\n",
    "\n",
    "    if current_depth == max_depth:\n",
    "        print('out of depth')\n",
    "        return taboo_list\n",
    "\n",
    "    if centre in taboo_list:\n",
    "        # we've been here before\n",
    "        print('Already been here.')\n",
    "        return taboo_list\n",
    "    else:\n",
    "        taboo_list.append(centre)\n",
    "\n",
    "    try:\n",
    "        userfname = os.path.join(USER_DIR, str(centre) + '.json')\n",
    "        if not os.path.exists(userfname):\n",
    "            print('Retrieving user details for twitter id %s' % str(centre))\n",
    "            while True:\n",
    "                try:\n",
    "                    user = api.get_user(centre)\n",
    "\n",
    "                    d = {'name': user.name,\n",
    "                         'screen_name': user.screen_name,\n",
    "                         'profile_image_url' : user.profile_image_url,\n",
    "                         'created_at' : str(user.created_at),\n",
    "                         'id': user.id,\n",
    "                         'friends_count': user.friends_count,\n",
    "                         'followers_count': user.followers_count,\n",
    "                         'followers_ids': user.followers_ids()}\n",
    "\n",
    "                    with open(userfname, 'w') as outf:\n",
    "                        outf.write(json.dumps(d, indent=1))\n",
    "\n",
    "                    user = d\n",
    "                    break\n",
    "                except tweepy.TweepError as error:\n",
    "                    print(type(error))\n",
    "\n",
    "                    if str(error) == 'Not authorized.':\n",
    "                        print('Can''t access user data - not authorized.')\n",
    "                        return taboo_list\n",
    "\n",
    "                    if str(error) == 'User has been suspended.':\n",
    "                        print('User suspended.')\n",
    "                        return taboo_list\n",
    "\n",
    "                    errorObj = error[0][0]\n",
    "\n",
    "                    print(errorObj)\n",
    "\n",
    "                    if errorObj['message'] == 'Rate limit exceeded':\n",
    "                        print('Rate limited. Sleeping for 15 minutes.')\n",
    "                        time.sleep(15 * 60 + 15)\n",
    "                        continue\n",
    "\n",
    "                    return taboo_list\n",
    "        else:\n",
    "            user = json.loads(file(userfname).read())\n",
    "\n",
    "        screen_name = enc(user['screen_name'])\n",
    "        fname = os.path.join(FOLLOWING_DIR, screen_name + '.csv')\n",
    "        friendids = []\n",
    "\n",
    "        if not os.path.exists(fname):\n",
    "            print('No cached data for screen name \"%s\"' % screen_name)\n",
    "            with open(fname, 'w') as outf:\n",
    "                params = (enc(user['name']), screen_name)\n",
    "                print('Retrieving friends for user \"%s\" (%s)' % params)\n",
    "\n",
    "                # page over friends\n",
    "                c = list(tweepy.Cursor(api.friends, id=user['id']).items())\n",
    "\n",
    "                friend_count = 0\n",
    "                while True:\n",
    "                    try:\n",
    "                        friend = next(c)\n",
    "                        friendids.append(friend.id)\n",
    "                        params = (friend.id, enc(friend.screen_name), enc(friend.name))\n",
    "                        outf.write('%s\\t%s\\t%s\\n' % params)\n",
    "                        friend_count += 1\n",
    "                        if friend_count >= MAX_FRIENDS:\n",
    "                            print('Reached max no. of friends for \"%s\".' % friend.screen_name)\n",
    "                            break\n",
    "                    except tweepy.TweepError:\n",
    "                        # hit rate limit, sleep for 15 minutes\n",
    "                        print('Rate limited. Sleeping for 15 minutes.')\n",
    "                        time.sleep(15 * 60 + 15)\n",
    "                        continue\n",
    "                    except StopIteration:\n",
    "                        break\n",
    "        else:\n",
    "            friendids = [int(line.strip().split('\\t')[0]) for line in file(fname)]\n",
    "\n",
    "        print('Found %d friends for %s' % (len(friendids), screen_name))\n",
    "\n",
    "        # get friends of friends\n",
    "        cd = current_depth\n",
    "        if cd+1 < max_depth:\n",
    "            for fid in friendids[:FRIENDS_OF_FRIENDS_LIMIT]:\n",
    "                taboo_list = get_follower_ids(fid, max_depth=max_depth,\n",
    "                    current_depth=cd+1, taboo_list=taboo_list)\n",
    "\n",
    "        if cd+1 < max_depth and len(friendids) > FRIENDS_OF_FRIENDS_LIMIT:\n",
    "            print('Not all friends retrieved for %s.' % screen_name)\n",
    "\n",
    "    except Exception as error:\n",
    "        print('Error retrieving followers for user id: ', centre)\n",
    "        print(error)\n",
    "\n",
    "        if os.path.exists(fname):\n",
    "            os.remove(fname)\n",
    "            print('Removed file \"%s\".' % fname)\n",
    "\n",
    "        sys.exit(1)\n",
    "\n",
    "    return taboo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] -s SCREEN_NAME -d DEPTH\n",
      "__main__.py: error: the following arguments are required: -s/--screen-name, -d/--depth\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-s\", \"--screen-name\", required=True, help=\"Screen name of twitter user\")\n",
    "    ap.add_argument(\"-d\", \"--depth\", required=True, type=int, help=\"How far to follow user network\")\n",
    "    args = vars(ap.parse_args())\n",
    "\n",
    "    twitter_screenname = args['screen_name']\n",
    "    depth = int(args['depth'])\n",
    "\n",
    "    if depth < 1 or depth > 5:\n",
    "        print('Depth value %d is not valid. Valid range is 1-5.' % depth)\n",
    "        sys.exit('Invalid depth argument.')\n",
    "\n",
    "    print('Max Depth: %d' % depth)\n",
    "    matches = api.lookup_users(screen_names=[twitter_screenname])\n",
    "\n",
    "    if len(matches) == 1:\n",
    "        print(get_follower_ids(matches[0].id, max_depth=depth))\n",
    "    else:\n",
    "        print('Sorry, could not find twitter user with screen name: %s' % twitter_screenname)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
